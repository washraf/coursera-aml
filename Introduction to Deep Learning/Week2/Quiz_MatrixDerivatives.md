## Question 1: Choose the correct statements about MLP implementation.
A backward pass of a dense layer needs a 4-d tensor derivative
You shouldn't prefer matrix operations when working with GPU
**You can write both passes of a dense layer with NumPy and make it quick even in Python**
**A forward pass of a dense layer can be done with matrix product**

## Question 2: How many dimensions will a derivative of a 3-d tensor by a 4-d tensor have?
7
*Each Dim in the second tensor m will be deepend n times from the effect of the first network so, the answer is n+m = 3+4 = 7*
## Question 3: 
2X_T