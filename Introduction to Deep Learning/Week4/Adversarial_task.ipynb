{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Adversarial-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "OwD7z_NgXNnl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generating human faces with Adversarial Networks\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week4/images/nvidia_cool_gan.png?raw=1\" width=\"400px\"/>\n",
        "_© research.nvidia.com_\n",
        "\n",
        "This time we'll train a neural net to generate plausible human faces in all their subtlty: appearance, expression, accessories, etc. 'Cuz when us machines gonna take over Earth, there won't be any more faces left. We want to preserve this data for future iterations. Yikes...\n",
        "\n",
        "Based on https://github.com/Lasagne/Recipes/pull/94 .\n"
      ]
    },
    {
      "metadata": {
        "id": "D5Cxd8Z1Xhmw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week3()\n",
        "setup_google_colab.setup_week4()\n",
        "# setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()\n",
        "\n",
        "# If you're using the old version of the course (check a path of notebook on Coursera, you'll see v1 or v2),\n",
        "# use setup_week2_old()."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SbuAUZpTXNnq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import grading\n",
        "import download_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V8FDmdtpXNny",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "download_utils.link_week_4_resources()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K915ogACXNn3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "plt.rcParams.update({'axes.titlesize': 'small'})\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "#The following line fetches you two datasets: images, usable for autoencoder training and attributes.\n",
        "#Those attributes will be required for the final part of the assignment (applying smiles), so please keep them in mind\n",
        "from lfw_dataset import load_lfw_dataset \n",
        "data,attrs = load_lfw_dataset(dimx=36,dimy=36)\n",
        "\n",
        "#preprocess faces\n",
        "data = np.float32(data)/255.\n",
        "\n",
        "IMG_SHAPE = data.shape[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wq20mOKyXNn7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#print random image\n",
        "plt.imshow(data[np.random.randint(data.shape[0])], cmap=\"gray\", interpolation=\"none\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Lb0XeG5XNoF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generative adversarial nets 101\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week4/images/noise_to_face.png?raw=1\" width=\"400px\"/>\n",
        "_© torch.github.io_\n",
        "\n",
        "Deep learning is simple, isn't it? \n",
        "* build some network that generates the face (small image)\n",
        "* make up a __measure__ of __how good that face is__\n",
        "* optimize with gradient descent :)\n",
        "\n",
        "\n",
        "The only problem is: how can we engineers tell well-generated faces from bad? And i bet you we won't ask a designer for help. \n",
        "\n",
        "__If we can't tell good faces from bad, we delegate it to yet another neural network!__\n",
        "\n",
        "That makes the two of them:\n",
        "* __G__enerator - takes random noize for inspiration and tries to generate a face sample. \n",
        "  * Let's call him __G__(z), where z is a gaussian noize.\n",
        "* __D__iscriminator - takes a face sample and tries to tell if it's great or fake. \n",
        "  * Predicts the probability of input image being a __real face__\n",
        "  * Let's call him __D__(x), x being an image.\n",
        "  * __D(x)__ is a predition for real image and __D(G(z))__ is prediction for the face made by generator.\n",
        "\n",
        "Before we dive into training them, let's construct the two networks."
      ]
    },
    {
      "metadata": {
        "id": "5ZijCP3NXNoH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras_utils import reset_tf_session\n",
        "s = reset_tf_session()\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras import layers as L"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "22CYRlU1XNoN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CODE_SIZE = 256\n",
        "\n",
        "generator = Sequential()\n",
        "generator.add(L.InputLayer([CODE_SIZE],name='noise'))\n",
        "generator.add(L.Dense(10*8*8, activation='elu'))\n",
        "\n",
        "generator.add(L.Reshape((8,8,10)))\n",
        "generator.add(L.Deconv2D(64,kernel_size=(5,5),activation='elu'))\n",
        "generator.add(L.Deconv2D(64,kernel_size=(5,5),activation='elu'))\n",
        "generator.add(L.UpSampling2D(size=(2,2)))\n",
        "generator.add(L.Deconv2D(32,kernel_size=3,activation='elu'))\n",
        "generator.add(L.Deconv2D(32,kernel_size=3,activation='elu'))\n",
        "generator.add(L.Deconv2D(32,kernel_size=3,activation='elu'))\n",
        "\n",
        "generator.add(L.Conv2D(3,kernel_size=3,activation=None))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nb4WLBw8XNoS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert generator.output_shape[1:] == IMG_SHAPE, \"generator must output an image of shape %s, but instead it produces %s\"%(IMG_SHAPE,generator.output_shape[1:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pyts1_ASXNoX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Discriminator\n",
        "* Discriminator is your usual convolutional network with interlooping convolution and pooling layers\n",
        "* The network does not include dropout/batchnorm to avoid learning complications.\n",
        "* We also regularize the pre-output layer to prevent discriminator from being too certain."
      ]
    },
    {
      "metadata": {
        "id": "riuq0IZ1XNoZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "discriminator = Sequential()\n",
        "\n",
        "discriminator.add(L.InputLayer(IMG_SHAPE))\n",
        "\n",
        "#<build discriminator body>\n",
        "\n",
        "discriminator.add(L.Conv2D(32,kernel_size=3,activation='elu'))\n",
        "discriminator.add(L.Conv2D(32,kernel_size=3,activation='elu'))\n",
        "discriminator.add(L.pooling.MaxPool2D(pool_size=2))\n",
        "discriminator.add(L.Conv2D(64,kernel_size=(5,5),activation='elu'))\n",
        "discriminator.add(L.Conv2D(64,kernel_size=(5,5),activation='elu'))\n",
        "discriminator.add(L.pooling.MaxPool2D(pool_size=2))\n",
        "discriminator.add(L.Conv2D(64,kernel_size=3,activation='elu'))\n",
        "\n",
        "discriminator.add(L.Flatten())\n",
        "discriminator.add(L.Dense(256,activation='tanh'))\n",
        "discriminator.add(L.Dense(2,activation=tf.nn.log_softmax))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q78l1-xkXNod",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "We train the two networks concurrently:\n",
        "* Train __discriminator__ to better distinguish real data from __current__ generator\n",
        "* Train __generator__ to make discriminator think generator is real\n",
        "* Since discriminator is a differentiable neural network, we train both with gradient descent.\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week4/images/gan.png?raw=1\" width=\"600px\"/>\n",
        "_© deeplearning4j.org_\n",
        "\n",
        "Training is done iteratively until discriminator is no longer able to find the difference (or until you run out of patience).\n",
        "\n",
        "\n",
        "### Tricks:\n",
        "* Regularize discriminator output weights to prevent explosion\n",
        "* Train generator with __adam__ to speed up training. Discriminator trains with SGD to avoid problems with momentum.\n",
        "* More: https://github.com/soumith/ganhacks\n"
      ]
    },
    {
      "metadata": {
        "id": "7cbvvY_7XNof",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "noise = tf.placeholder('float32',[None,CODE_SIZE])\n",
        "real_data = tf.placeholder('float32',[None,]+list(IMG_SHAPE))\n",
        "\n",
        "logp_real = discriminator(real_data)\n",
        "\n",
        "generated_data = generator(noise)\n",
        "\n",
        "logp_gen = discriminator(generated_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZB4BjSGJXNol",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########################\n",
        "#discriminator training#\n",
        "########################\n",
        "\n",
        "d_loss = -tf.reduce_mean(logp_real[:,1] + logp_gen[:,0])\n",
        "\n",
        "#regularize\n",
        "d_loss += tf.reduce_mean(discriminator.layers[-1].kernel**2)\n",
        "\n",
        "#optimize\n",
        "disc_optimizer =  tf.train.GradientDescentOptimizer(1e-3).minimize(d_loss,var_list=discriminator.trainable_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SJ6JMQBVXNoq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########################\n",
        "###generator training###\n",
        "########################\n",
        "\n",
        "g_loss = -tf.reduce_mean(logp_gen[:,1])\n",
        "\n",
        "gen_optimizer = tf.train.AdamOptimizer(1e-4).minimize(g_loss,var_list=generator.trainable_weights)\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ItLFVG0XNov",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-8HKqLCzXNo2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Auxiliary functions\n",
        "Here we define a few helper functions that draw current data distributions and sample training batches."
      ]
    },
    {
      "metadata": {
        "id": "pah4BRZWXNo4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_noise_batch(bsize):\n",
        "    return np.random.normal(size=(bsize, CODE_SIZE)).astype('float32')\n",
        "\n",
        "def sample_data_batch(bsize):\n",
        "    idxs = np.random.choice(np.arange(data.shape[0]), size=bsize)\n",
        "    return data[idxs]\n",
        "\n",
        "def sample_images(nrow,ncol, sharp=False):\n",
        "    images = generator.predict(sample_noise_batch(bsize=nrow*ncol))\n",
        "    if np.var(images)!=0:\n",
        "        images = images.clip(np.min(data),np.max(data))\n",
        "    for i in range(nrow*ncol):\n",
        "        plt.subplot(nrow,ncol,i+1)\n",
        "        if sharp:\n",
        "            plt.imshow(images[i].reshape(IMG_SHAPE),cmap=\"gray\", interpolation=\"none\")\n",
        "        else:\n",
        "            plt.imshow(images[i].reshape(IMG_SHAPE),cmap=\"gray\")\n",
        "    plt.show()\n",
        "\n",
        "def sample_probas(bsize):\n",
        "    plt.title('Generated vs real data')\n",
        "    plt.hist(np.exp(discriminator.predict(sample_data_batch(bsize)))[:,1],\n",
        "             label='D(x)', alpha=0.5,range=[0,1])\n",
        "    plt.hist(np.exp(discriminator.predict(generator.predict(sample_noise_batch(bsize))))[:,1],\n",
        "             label='D(G(z))',alpha=0.5,range=[0,1])\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l1BxL_WeXNo9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training\n",
        "Main loop.\n",
        "We just train generator and discriminator in a loop and plot results once every N iterations."
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "8cmmJhEKXNo_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "\n",
        "for epoch in tqdm_utils.tqdm_notebook_failsafe(range(50000)):\n",
        "    \n",
        "    feed_dict = {\n",
        "        real_data:sample_data_batch(100),\n",
        "        noise:sample_noise_batch(100)\n",
        "    }\n",
        "    \n",
        "    for i in range(5):\n",
        "        s.run(disc_optimizer,feed_dict)\n",
        "    \n",
        "    s.run(gen_optimizer,feed_dict)\n",
        "    \n",
        "    if epoch %100==0:\n",
        "        display.clear_output(wait=True)\n",
        "        sample_images(2,3,True)\n",
        "        sample_probas(1000)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yZrDwx4xXNpH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from submit_honor import submit_honor\n",
        "submit_honor((generator, discriminator), \"eng_walid_ashraf@hotmail.com\", \"TPIvAzUcaqEypBhB\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "JmKxA3ZAXNpS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#The network was trained for about 15k iterations. \n",
        "#Training for longer yields MUCH better results\n",
        "plt.figure(figsize=[16,24])\n",
        "sample_images(16,8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dCwOE_ejXNpe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ap4PyEs5XgTk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}